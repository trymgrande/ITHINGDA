# 1
## 1
Index terms are important for allowing accurate results. The most important criteria for determining index terms are:
- Uniqueness (discriminative): needs to be able to separate the specific document.
- Representative: Needs to represent the content of the document.
- Space efficient: Needs to be compressed compared to the document itself.
- Semantic: needs to say something about the semantics of the document.

## 2
![](2021-11-24-15-21-13.png)

## 3
IR:
- unstructured data
- partial matches
- ranked results
DR:
- structured data
- exact matches
- unranked results
Netflix uses information retrieval in order to find the correct movie the user is looking for by using text search. Data retrieval will then be used to fetch the given movie from the database using an exact ID.

# 2
## 1
Text retrieval is based on language, while multimedia (image) retrieval is based on shapes. This can be examplified by looking at each method, where TR uses word tokenizing, stemming, other formatting...while MR is not able to use this. Semantic extraction is more challenging with MR, as pixels are independent of each other and the semantics can be of any dimension/size/rotation, unlike sentences that are stringed together. Therefore, good features are required to be able to properly compare images.

## 2
Features are properties that can be extracted from images in order to make them separated from the rest. Therefore, features need to be as discriminative as possible. Examples are: Corners, edges, color layout, color histogram, textures.

## 3
Object (spatial, temporal, comp)
Object layer (image, video, audio)
Compression (raw, compressed)
Format (greyscale, colour, jpeg, jbig, dpcm, mp3, mp4)

# 3
## 1
### a
Lexicographical analysis involves tokenizing a text into words while also stemming the words to make sure no "distinct" words are repeated, including converting to lowercase. Stop word removal means to filter out words that add little meaning to the text.

«**Competition** **enforcers** on both **sides** of the **Atlantic** are now **looking** into how **dominant** **tech** **companies** **use** and **monetise** **data**»

Assuming stop words: {on, of, the, are, how, and, both, now, into}

Result:
{"competition", "enforcers", "sides", "Atlantic", "looking", "dominant", "tech", "companies", "use", "monitize", "data"}




### b
Trie:
![](2021-11-24-18-18-32.png)

### c
Inverted index is a data structure that references words to its index. This can be used by creating an index array that references the indexed words in a document. For this context, it will look like this:
E.g.:
![](2021-11-24-18-19-05.png)
From this array, we can quickly and efficiently find the occurence in the document for each word. This is standardised by alphabetically sorting.

## 2
![](2021-11-24-19-26-12.png)

# 4
## 1
Language model:
Uses assigned probability for each term. Can iterate with any number of sequential terms.

Vector space model:
Uses weighted terms to determine cosine similarity between documents. 

## 2
Probobalistic model:
Estimates probability of relevance given a query.

Language model
Estimates probability of a document's model generating a given query.

# 5
## 1
APd = Average precision for all ranks of given document d
MAP = average precision for all Pd

## 2
P = rel ret/ret
R = rel ret/rel

P(R)=

ret = 20
rel ret = 7
rel = 8

### a
P = 7/20 = 0.35
R = 7/8 = 0.875

### b
F = 2PR/(P+R) = 2*0.35*0.875/(0.35+0.875) = 0.5

### c
| Rank | REL? | Precision | Recall    |
|------|------|-----------|-----------|
| 1    | yes  | 1/1=1     | 1/8=0.13  |
| 2    | no   | 1/2=0.5   | 1/8=0.13  |
| 3    | yes  | 2/3=0.67  | 2/8=0.25  |
| 4    | yes  | 3/4=0.75  | 3/8=0.375 |
| 5    | no   | 3/5=0.6   | 3/8=0.375 |
| 6    | no   | 3/6=0.5   | 3/8=0.375 |
| 7    | yes  | 4/7=0.57  | 4/8=0.5   |
| 8    | yes  | 5/8=0.63  | 5/8=0.625 |
| 9    | no   | 5/9=0.56  | 5/8=0.625 |
| 10   | yes  | 6/10=0.6  | 6/8=0.75  |
| 11   | no   | 6/11=0.55 | 6/8=0.75  |
| 12   | no   | 6/12=0.5  | 6/8=0.75  |
| 13   | no   | 6/13=0.46 | 6/8=0.75  |
| 14   | no   | 6/14=0.43 | 6/8=0.75  |
| 15   | yes  | 7/15=0.47 | 7/8=0.875 |

### d
R-precision:
1: 1
2: 0.5
3: 0.33
etc..(col rank, precision)

R(rel) = R(8) = 0.63

### e
| Recall level | Precision level |
|--------------|-----------------|
| 0            | 1               |
| 1            | 1               |
| 2            | 0.75            |
| 3            | 0.75            |
| 4            | 0.63            |
| 5            | 0.63            |
| 6            | 0.63            |
| 7            | 0.6             |
| 8            | 0.47            |
| 9            | 0               |
| 10           | 0               |

# 6
# 1
## 1
1

## 2
2

## 3
1

## 4
3

## 5
1

## 6
3

## 7
4

## 8
1

## 9
4

## 10
1
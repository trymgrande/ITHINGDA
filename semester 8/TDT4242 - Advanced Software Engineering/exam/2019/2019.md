# 1
## 1
<!-- - why/how forward/backward traceability -->
We may need forward traceability to ensure all requirements are implemented, and to be able to perform change impact analysis. 
In a similar way, we ma need backward traceability to avoid "gold plating", i.e. working on a task past the reasoning of the requirement. Being able to perform change impact analysis, defect impact analysis, as well as performing root cause analysis of defects.

This is implemented by documenting the path from creation to implementation including all the steps in between, e.g. a traceability matrix.

NOTE: also trace tagging

## 2
Static backward slicing is a slice with respect to a variable v at a certain breaking point p in the program with the set of statements that contributed to the value of the variable v at p. This means that the slicing of v at p denotes the set of nodes in the control flow graph that affected the value of v at p. This helps in terms of finding errors, as well as understanding the control flow of a variable in isolation.

## 3
<!-- Explain decomposition-based, call-graph based, and path-based integration testing strategies and 
compare their pros and cons. (6 points)  -->
There are multiple integration testing strategies.

**Decomposition-based** relies on function decomposition trees by utilizing a top down or bottum up approach.
Top down means starting implementaion from the top node, meaning starting from main. The functions here are implemented with function calls down to the next nodes. These nodes will contain stubs to simulate functions. Development is incremented by going down the tree once all methods are implemented for a given level until the leaves are reached and implemented as well. Bottom up will be the opposite, meaning functions are implemented at the leaves first, and using drivers in all the nodes above. These drivers are functions that will be replaced once development is iterated upwards. A combination of these is called a sandwich, where some nodes will implement one method, while others will implement the other. This leads to incremental and intuitive development and easy fault isolation but with the need for implementation of stubs and/or drivers.

**Call-graph based** uses actual components instead of stubs or drivers, which can save time. There are two strategies, pairwise integration, and neighborhoods integration. Pairwise integration focuses on communication between one node pair at a time. Neighborhoods integration works in a similar way, but by looking at all successors of a node up to a given depth level, instead of one pair at a time. These are both limited to local integration, however, and may cause problems during larger integrations.

**path-based integration** focuses on interactions rather than interfaces between components. This works by looking at all paths from all to all nodes.(?)

<!-- 4) Explain the general regression test selection process. (3 points)  -->
In the corrective general regression selection process does not retest all cases, neither does it randomly select them. Instead, it uses a techniqe for safe regression test selection that keeps all tests that cover changed code. This helps catching cases, but does not select them or update code itself, which both have to be done manually. 

The general selection process starts with establishing traces between program and test set, that is used to record entities while running tests while executing program. After testing, the code is modified, and the test will be ran again only on the changed part of the code. 

This method can be classified based on entities traced and compared:
dynamic slicing (statements), graph-walk approach (nodes in graph), firewall approach.

<!-- 5) Explain the essential ideas of the two types of standards to verify safety-critical systems. (2 points)  -->


<!-- 6) Explain what adaptive random test is and its benefits. (3 points)  -->
The test inputs are selected from the randomly generated set that is specifically uniform over the input domain. This method is shown empirically to be 50% more efficient than normal random testing.

<!-- 7) Explain why code inspection and testing are complementary. (4 points)  -->
Code inspection is an important part of testing the code, as one often needs to know the details about how the code works, especially with white box testing.
 
<!-- 8) Explain MySQL dual licensing. (2 points)  -->
Allows using a combination of both open source GPL as well as commercial licensing.

<!-- 9) Based on the content of the guest lecture “coordination in large-scale agile development,” describe 
some coordination challenges and possible solutions in large scale agile projects. (3 points) -->

# 2
## requirements
<!-- ambiguity, inconsistency, forward referencing, and opacity. -->
- some numbers of the trucks can drive autonomously, and others by humans
- autonomous trucks should drive at default speed
- truck platooning can drive along the route we set in GPS before the 
journey and follow the human drivers’ command to change the route
- autonomous trucks should have three chairs for the drivers
- trucks should drive safely
    - shuld have sensors for obstacle avoidance
        - should stop in case of obstacles on the road
- drive efficiently
    - minimize distance between each other and maximize collective speed
- use sensors to detect distances and speed of trucks

## 1 - quality issues
ambiguity:
everything🖕
- "some number" - how many?


inconsistency:
- autonomous trucks don't need driver seats
- driving efficiently while also maximizing collective speed is impossible
- driving at default speed while also maximizing collective speed is impossible

forward referencing:
- "default speed"


opacity:
- autonomous trucks should have three chairs for the drivers

## 2
agent AT - autonomous truck
agent HD - human driver
agent NAT- non-autonomous truck

finding new requirements are left as an exercise to the reader.



## 3

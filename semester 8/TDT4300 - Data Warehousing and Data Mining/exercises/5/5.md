# 1


# 2
| TID | Transaction |
|-----|-------------|
| T1  | BF          |
| T2  | ABCDFH      |
| T3  | ABF         |
| T4  | ABFH        |
| T5  | ADEF        |
| T6  | ABFH        |
| T7  | ABDEFH      |
| T8  | AGH         |

## frequent itemset genen

minsup = 4

k=1

C1
| itemset | support |
|---------|---------|
| A       | 7       |
| B       | 6       |
| C       | 1       |
| D       | 3       |
| E       | 2       |
| F       | 7       |
| G       | 1       |
| H       | 5       |

eliminate all itemsets with support < minsup

L1
| itemset | support |
|---------|---------|
| A       | 7       |
| B       | 6       |
| F       | 7       |
| H       | 5       |

find support of combinations

k=2

C2
| itemset | support |
|---------|---------|
| A,B     | 5       |
| A,F     | 6       |
| A,H     | 5       |
| B,F     | 6       |
| B,H     | 4       |
| F,H     | 4       |

eliminate all itemsets with support < minsup

L2
| itemset | support |
|---------|---------|
| A,B     | 5       |
| A,F     | 6       |
| A,H     | 5       |
| B,F     | 6       |
| B,H     | 4       |
| F,H     | 4       |

k=3

find support of combinations

C3
| itemset | support |
|---------|---------|
| A,B,F   | 5       |
| A,B,H   | 4       |
| A,F,H   | 4       |
| B,F,H   | 4       |

eliminate all itemsets with support < minsup

L3
| itemset | support |
|---------|---------|
| A,B,F   | 5       |
| A,B,H   | 4       |
| A,F,H   | 4       |
| B,F,H   | 4       |

k=4

C4

| itemset | support |
|---------|---------|
| A,B,F,H | 4       |

## confidence

A confidence of 60% means that 60% of the customers, who purchased milk and bread also bought butter.

Confidence(A->B)=Support_count(A∪B)/Support_count(A)

subset => itemset - subset
a => abfh - a
a => bfh


| rule  | confidence |
|-------|------------|
| A=>BF |  5/          |
| A=>BH |            |
| A=>FH |            |
| B=>AF |            |
| B=>AH |            |
| B=>FH |            |
| F=>AB |            |
| F=>AH |            |
| F=>BH |            |
| H=>AB |            |
| H=>AF |            |
| H=>BF |            |
| BF=>A |            |
| BH=>A |            |
| FH=>A |            |
| AF=>B |            |
| AH=>B |            |
| FH=>B |            |
| AB=>F |            |
| AH=>F |            |
| BH=>F |            |
| AB=>H |            |
| AF=>H |            |
| BF=>H |            |


<!-- | rule     | confidence |
|----------|------------|
| A=>B ^ F ^ H | 4/7=0.57   |
| A ^ B=>F ^ H | 4/5=0.8    |
| A ^ F=>B ^ H | 4/6=0.67   |
| A ^ H=>B ^ F | 4/5=0.8    |
| A ^ B ^ F=>H | 4/5=0.8    |
| A ^ B ^ H=>F | 4/4=1      |
| A ^ F ^ H=>B | 4/4=1      |
| B=>A ^ F ^ H | 4/6=0.67   |
| B ^ F=>A ^ H | 4/6=0.67   |
| B ^ H=>A ^ F | 4/4=1      |
| B ^ F ^ H=>A | 4/4=1      |
| F=>A ^ B ^ H | 4/7=0.57   |
| F ^ H=>A ^ B | 4/4=1      |
| H=>A ^ B ^ F | 4/5=0.8    | -->

remove rules with confidence < minconf=0.75

high confidence rules

<!-- | rule     | confidence |
|----------|------------|
| A ^ B=>F ^ H | 4/5=0.8    |
| A ^ H=>B ^ F | 4/5=0.8    |
| A ^ B ^ F=>H | 4/5=0.8    |
| A ^ B ^ H=>F | 4/4=1      |
| A ^ F ^ H=>B | 4/4=1      |
| B ^ H=>A ^ F | 4/4=1      |
| B ^ F ^ H=>A | 4/4=1      |
| F ^ H=>A ^ B | 4/4=1      |
| H=>A ^ B ^ F | 4/5=0.8    | -->

# 3

## 1
### a
- Tree pruning is useful for shortening time spend generating trees. 
- Need a test set, meaning less data for training, and low accuracy on evaluation if test set is small.

### b
- typical stopping conditions
    - all instances belong to same class
    - all attribute values are the same
- more restrictive conditions
    - number of instances is less than given threshold
    - class distribution of instances are independent of the available features (not e.g. 50/50 for 2 features ?)
    - stop if impurity measures don't improve on expansion e.g. gini / information gain

### c

### d
| attribute        | x      | y-yes-count | y-no-count |
|------------------|--------|-------------|------------|
| age              | young  | 4           | 3          |
| age              | middle | 5           | 1          |
| age              | old    | 3           | 4          |
| income           | low    | 4           | 2          |
| income           | medium | 6           | 3          |
| income           | high   | 2           | 3          |
| married          | yes    |             |            |
| married          | no     |             |            |
| student          | yes    |             |            |
| student          | no     |             |            |
| creditworthyness | pass   |             |            |
| creditworthyness | high   |             |            |

age
young
<!-- E(pc_on_credit, age) = P(young)*E(4,3) + P(middle)*E(5,1) + P(old)*E(3,4) -->
E = -C1*log(C1)-C2*log(C2)

P(C1_young) = 4/7
P(C2_young) = 3/7
E(young) = -(4/7)*log2(4/7)-(3/7)*log2(3/7)
IG_young = E(young)*P(young) = 0.985228136*(7/20)
=0.34 (wrong)

P(C1_middle) = 5/6
P(C2_middle) = 1/6

P(C1_old) = 3/7
P(C2_old) = 4/7

# 4
age in years
quantitative, discrete, numeric ratio
(a) Time in terms of AM and PM.
symmetric binary, nominal, categorical, qualitative
(b) Brightness as measured by a light meter.
numeric quantitative ratio, continous
(c) Brightness as measured by people’s judgments. 
discrete, categorical qualitative, ordinal
(d) Angles as measured in degrees between 0 and 360. 
continuous, quantitative (ratio)
(e) Bronze, Silver, and Gold medals as awarded at the Olympics. 
discrete, qualitative (ordinal)
(f) Height above sea level. 
continuous, quantitative (ratio)
(g) Number of patients in a hospital. 
discrete, quantitive (ratio)
(h) ISBN numbers for books. (Look up the format on the Web.) 
discrete, qualitative (nominal)
(i) Ability to pass light in terms of the following values: opaque, translucent, transparent.
discrete, qualitative (ordinal)
(j) Military rank.
discrete, qualitative (ordinal)
(k) Distance from the center of campus. 
continous, quantitative (ratio)
(l) Density of a substance in grams per cubic centimeter
continuous, quantitative (ratio)
(m) Coat check number. (When you attend an event, you can often give your coat to someone
who, in turn, gives you a number that you can use to claim your coat when you leave.)
continous, qualitative (nominal)


# 5


# 6
## 1
### a
Noise is never though of as directly interesting or desireable as it is not an actual part of the data source. One use for it would be to use it in order to reduce noise in the future. Outliers are a part of the data source, and can therefore be used, but might be harder to use compared to the rest of the data. This can often be misidentified as noise.

### b
Noise objects can be outliers.

### c
No, it usually is closely attributed to the real data.

### d
No, outliers can be real, but unconsistant data.

### e
Yes, in theory, there can be a lot of one sided noise, which can skew our view of the data, causing the actual data to look like outliers/noise.

# 7
a
x = (1,1,1,1)
y = (2,2,2,2)

cosine:
x*y = 1*2+1*2+1*2+1*2 = 8
||x|| = sqrt(1*1+1*1+1*1+1*1) = 2
||y|| = sqrt(2*2+2*2+2*2+2*2) = 4

(x*y)/(|1x|1 1|y|1)
8/8 = 1

correlation
corr(x,y) = cov(x,y) / std_dev(x) * std_dev(y)

cov:
((1-1+1-1+1-1+1-1)*(2-2+2-2+2-2+2-2))/3=0

std_dev:
avg(x) = 1
avg(y) = 2

std_dev(x) = 0
std_dev(y) = 0

corr(x,y) = 0/0*0 = 0/0 (undefined)

b

jaccard:
(A^B)/(AUB) 
0/4=0


euclidean:
sqrt((x1-y1)²+(x2-y2)² ...)

sqrt((0-1)²+(1-0²)+(0-1)²+(1-0²))
=2

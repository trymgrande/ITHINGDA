{"cells":[{"cell_type":"markdown","source":["#### Names of people in the group"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bbe62928-01d3-402d-9e45-19d009a4639d"}}},{"cell_type":"markdown","source":["Thomas Bjerke\n\nTrym Grande"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"15e1606f-bbea-4e98-9f90-bf0a15da5391"}}},{"cell_type":"code","source":["from pyspark.sql.session import SparkSession\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"389ff132-7e3c-444e-a980-6490e3448153"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# A helper function to load a table (stored in Parquet format) from DBFS as a Spark DataFrame \ndef load_df(table_name: \"name of the table to load\") -> DataFrame:\n    return spark.read.parquet(table_name)\n  \nusers_df = load_df(\"dbfs:/FileStore/dataframes/users\")\nposts_df = load_df(\"dbfs:/FileStore/dataframes/posts\")\ncomments_df = load_df(\"dbfs:/FileStore/dataframes/comments\")\nbadges_df = load_df(\"dbfs:/FileStore/dataframes/badges\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1b384d61-f63a-4c3f-9d87-63e0427c5ecd"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### The problem: mining the interests of experts\n\nThe primary role of a questions and answering platform such as Stack Exchange is to connect two types of people. Namely, people who have questions in areas such as computer science or data science and knowledgeable people who can answer those questions reliably. Let's call the first category of people' knowledge seekers' and the second one 'expert users' or 'experts' for short.\n\nHere we want to answer a question related to the diversity of topics that experts are interested in using our data. We want to know if expert users only answer questions in a specific set of topics or their interests include a wide variety of topics.\n\nTo answer the above question, we will compute the correlation between a user's expertise level and the diversity of topics of questions they have answered. The first step is to define two variables (or measures); first for 'user expertise level' and then for 'user interest diversity'. Then we will use the Pearson correlation coefficient to measure the linear correlation between the two variables. We define the variables as:\n\n   - VariableA (the measure of user expertise level). We will use the 'Reputation' column from 'users' table, which according to Stack Exchange's documentation \"is a rough measurement of how much the community trusts you; it is earned by convincing your peers that you know what you're talking about\" as an indicator of a user's expertise level on the platform. \n\n   - VariableB (The measure of user interest diversity). We measure the diversity of a user's interests by computing the total number of distinct tags associated with the questions each user has answered divided by the total number of unique tags which is 638.\n\nCompute the Pearson correlation coefficient between VariableA and VariableB, and based on the result you've got, answer the following question: \n\n     Do expert users have specif interests or do they have general interests?\n\nPlease explain your reasoning on how you reached your answer.\n\nYou should use Apache Spark API for your implementation. You can use the Spark implementation of the Pearson correlation coefficient."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e9b9e457-0510-45fb-8a13-85c006247f0c"}}},{"cell_type":"markdown","source":["### Calculate variable A"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e4d361a-829b-4c71-a39f-ff7b33d299d9"}}},{"cell_type":"code","source":["variable_a = users_df['Id', 'Reputation']\nvariable_a.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"02f6bd7b-4da1-4bef-92d3-c32266d0c025"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+----------+\n| Id|Reputation|\n+---+----------+\n| -1|         1|\n|  1|       101|\n|  2|       101|\n|  3|       101|\n|  4|       101|\n|  5|       215|\n|  6|       101|\n|  7|       101|\n|  8|       101|\n|  9|      1102|\n| 10|       101|\n| 11|       213|\n| 12|       101|\n| 14|      2782|\n| 15|       101|\n| 16|         1|\n| 17|       236|\n| 18|       101|\n| 19|       101|\n| 20|       101|\n+---+----------+\nonly showing top 20 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+----------+\n| Id|Reputation|\n+---+----------+\n| -1|         1|\n|  1|       101|\n|  2|       101|\n|  3|       101|\n|  4|       101|\n|  5|       215|\n|  6|       101|\n|  7|       101|\n|  8|       101|\n|  9|      1102|\n| 10|       101|\n| 11|       213|\n| 12|       101|\n| 14|      2782|\n| 15|       101|\n| 16|         1|\n| 17|       236|\n| 18|       101|\n| 19|       101|\n| 20|       101|\n+---+----------+\nonly showing top 20 rows\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["def run_query(query: str, df1: DataFrame, df2: DataFrame, df3=None):\n    df3: DataFrame\n    df1.createOrReplaceTempView(\"df1\")\n    df2.createOrReplaceTempView(\"df2\")\n    if df3 is not None: \n      df3.createOrReplaceTempView(\"df3\")\n    sql_df = spark.sql(query)\n    return sql_df"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fdb69317-dae4-4b7d-9c10-dc0b9895f354"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# join users, posts, comments\nquery = \"\"\"\nSELECT df1.Id, df3.tags FROM \ndf1 JOIN df2 ON df1.Id = df2.UserId\nJOIN df3 on df2.PostId = df3.Id\nORDER BY df1.Id\n\"\"\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c18a25d-e111-417f-8ffa-82139d3a38b4"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["user_tags_df = run_query(query, users_df, comments_df, posts_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"717b4686-f208-468f-a43b-4f171baeea2e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Calculate variable B"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b215ca2f-3fcd-4755-b0e7-18c6e8eb3104"}}},{"cell_type":"code","source":["def user_interest_wideness(user_tags_df: DataFrame):\n  \"\"\"\n  Param user_tags_df:\n    DataFrame containing user id on column 0, and tags on column 1\n  Returns new DataFrame containing distinct user ids along with the respective distinct tag count divided by the total number of tags\n  \"\"\"\n  TOTAL_TAG_NUMBER = 638\n  \n  # get tags column from dataframe and convert to list of tag lists\n  tags_list = (user_tags_df.select('tags').rdd.flatMap(lambda x: x).collect())\n  ids = (user_tags_df.select('Id').rdd.flatMap(lambda x: x).collect())\n  \n  # aggregate into list of distinct tags for each distinct user\n  id_pointer = float('-inf')\n  data = [] # user_id, labels\n  for (user_id, tags) in zip(ids, tags_list):\n    if tags is None: continue\n    tags = tags[1:-1].split('><')\n    if user_id != id_pointer: # new user\n      id_pointer = user_id\n      data.append([user_id, []])\n    \n    # append tags to the same user\n    data[len(data)-1][1].extend([tag for tag in tags if tag not in data[len(data)-1][1]])\n  \n  # replace labels with a count of the labels\n  for i in range(len(data)):\n    data[i][1] = len(data[i][1])/TOTAL_TAG_NUMBER\n  \n  # create new dataframe with the new modified data\n  columns = ['UserId', 'TagBroadness']\n  result_df = spark.createDataFrame(data, columns)\n  return result_df\n\nvariable_b = user_interest_wideness(user_tags_df)\nvariable_b.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"90c9f375-7905-431a-bdcf-6a26bb02a037"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+------+--------------------+\n|UserId|        TagBroadness|\n+------+--------------------+\n|     6|0.004702194357366771|\n|    11|0.001567398119122257|\n|    14|  0.0109717868338558|\n|    17|  0.0109717868338558|\n|    21| 0.24921630094043887|\n|    24|0.006269592476489028|\n|    26|0.012539184952978056|\n|    31|0.004702194357366771|\n|    34|0.004702194357366771|\n|    36|0.009404388714733543|\n|    41|0.003134796238244514|\n|    51|0.009404388714733543|\n|    53|0.003134796238244514|\n|    59|0.004702194357366771|\n|    62|0.014106583072100314|\n|    66|0.003134796238244514|\n|    70|0.004702194357366771|\n|    75| 0.05329153605015674|\n|    77|0.009404388714733543|\n|    82|0.009404388714733543|\n+------+--------------------+\nonly showing top 20 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------+--------------------+\n|UserId|        TagBroadness|\n+------+--------------------+\n|     6|0.004702194357366771|\n|    11|0.001567398119122257|\n|    14|  0.0109717868338558|\n|    17|  0.0109717868338558|\n|    21| 0.24921630094043887|\n|    24|0.006269592476489028|\n|    26|0.012539184952978056|\n|    31|0.004702194357366771|\n|    34|0.004702194357366771|\n|    36|0.009404388714733543|\n|    41|0.003134796238244514|\n|    51|0.009404388714733543|\n|    53|0.003134796238244514|\n|    59|0.004702194357366771|\n|    62|0.014106583072100314|\n|    66|0.003134796238244514|\n|    70|0.004702194357366771|\n|    75| 0.05329153605015674|\n|    77|0.009404388714733543|\n|    82|0.009404388714733543|\n+------+--------------------+\nonly showing top 20 rows\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Calculate Pearson correlation using variables A and B"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e0805d6b-ffe2-47b4-9241-cce929886d22"}}},{"cell_type":"code","source":["# join variable a and b on user id into the same dataframe\nquery = \"SELECT * FROM df1 JOIN df2 ON df1.Id = df2.UserId\"\ndf = run_query(query, variable_a, variable_b)\n\n# calculate pearson coefficient\npearson = df.corr(\"Reputation\", \"TagBroadness\", \"pearson\")\nprint(pearson)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"60a972c5-ae3f-4889-a34d-51bce258c5ac"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"0.7113864805661866\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["0.7113864805661866\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Results\nThe results show that expert users have a positive and high correlation (0.71) to having general interests. This means that expert users have *general* interests."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f1564f70-d86a-46cd-a0d4-e602793dd5bb"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Task4","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":118798763941686}},"nbformat":4,"nbformat_minor":0}

# 1
Oppg. 1 – Big Data-rammeverk – 15 % (lik vekting for a, b og
c)
a) Diskuter i kva grad rammeverka MapReduce, Spark, og Storm er eigna til sanntids-
prosessering av innkomande data.

MapReduce
- slow as it runs operations on disk
- limited to batch processing of one job at a time
- usually used as a data warehousing tool rather than data analysis because of these reasons


Spark
- can run tasks in parallel
- Use micro-batching / batch (spark core)
- runs 100x faster in memory, or 10x faster on disk
    - depends on whether all the data fits in memory or not
    - if so, fast but expensive
- delivery guarantees exactly once
- uses its own streaming API rather than hadoop YARN
- can be installed on top of hadoop in order to benefit from hdfs
- processess events in batches, meaning a few seconds of latency

Storm
- can run tasks in parallel
- Use event-streaming
- delivery guarantees at most once / at least once
- uses set of spouts and bolts
    - spouts are sorces
    - bolts are functions that produce new streams from a source (spout)
    - often makes up a network
- can be installed on top of hadoop and read/write files to hdfs
    - does not run on hadoop clusters, but uses zookeeper and its own minion worker to manage processes
- processes each event one at a time, meaning milliseconds of latency


b) Kva kjenneteikner dei av transformasjonane («transformations») i Spark som har høg kostnad,
og kva er årsaka/årsakene til høg kostnad? 

Wide transforations are expensive when compared to narrow ones. This is because they involve a process called shuffling. This process occurs when the data in a single partitions may live in many partitions of the parent RDD. This means that the data is shuffled between partitions during the transformation, which is costly.

c) Gå ut frå at du er ansvarleg for ei Hadoop-klynge, beståande av 30 maskiner. Brukarane klager
over at applikasjonane deira har lengre responstid enn før. Diskuter kva som kan vere potensielle
årsaker til dette, og kor høg grad av sannsynlighet kvar årsak har (høg/lav).

An increase in response time given a constant number of computer nodes, usually means an increase in users, causing an increased request frequency. This will then cause the response time to be higher as the computational power per request will be lower.
- cpu demanding applications
- network demanding requests
- generally more users

# 2
Oppg. 2 – Shingles, minhashing, og LSH – 20 % (lik vekting på
a og b)
Vi har i denne oppgaven fem sett (S0, S1, S2, S3, S4), og ønsker å bruke LSH for å finne like sett.
Anta følgende tabell, som viser de fem settene og 2-shingler som er inneholdt i disse:

| Row/x | k-shingle | S0 | S1 | S2 | S3 | S4 |
|-------|-----------|----|----|----|----|----|
| 0     | aa        | 1  | 0  | 1  | 1  | 1  |
| 1     | ab        | 1  | 1  | 0  | 0  | 0  |
| 2     | ac        | 0  | 0  | 0  | 1  | 1  |
| 3     | ba        | 1  | 1  | 0  | 0  | 0  |

Anta at vi ønsker å generere MinHash-signaturer med lengde 4, med permutasjoner gitt av fire
hash-funksjoner h1(x), h2(x), h3(x) og h4(x), som har følgende verdier for x:

| x | h1(x) | h2(x) | h3(x) | h4(x) |
|---|-------|-------|-------|-------|
| 0 | 1     | 3     | 0     | 2     |
| 1 | 3     | 1     | 2     | 0     |
| 2 | 2     | 0     | 3     | 1     |
| 3 | 0     | 2     | 1     | 3     |

a) Hva blir signaturene for de 5 settene? Forklar hvordan du kommer frem til disse.
for each row
update only columns with respective value 1
replace its hash value if it's lower

| Row/x | k-shingle | S0 | S1 | S2 | S3 | S4 | x | h1(x) | h2(x) | h3(x) | h4(x) |
|-------|-----------|----|----|----|----|----|---|-------|-------|-------|-------|
| 0     | aa        | 1  | 0  | 1  | 1  | 1  | 0 | 1     | 3     | 0     | 2     |
| 1     | ab        | 1  | 1  | 0  | 0  | 0  | 1 | 3     | 1     | 2     | 0     |
| 2     | ac        | 0  | 0  | 0  | 1  | 1  | 2 | 2     | 0     | 3     | 1     |
| 3     | ba        | 1  | 1  | 0  | 0  | 0  | 3 | 0     | 2     | 1     | 3     |


|    | S0 | S1 | S2 | S3 | S4 |
|----|----|----|----|----|----|
| h1 | ∞  | ∞  | ∞  | ∞  | ∞  |
| h2 | ∞  | ∞  | ∞  | ∞  | ∞  |
| h3 | ∞  | ∞  | ∞  | ∞  | ∞  |
| h4 | ∞  | ∞  | ∞  | ∞  | ∞  |

| R0      | S0 | S1 | S2 | S3 | S4 |
|---------|----|----|----|----|----|
| updated | x  |    | x  | x  | x  |
| h1      | 1  | ∞  | 1  | 1  | 1  |
| h2      | 3  | ∞  | 3  | 3  | 3  |
| h3      | 0  | ∞  | 0  | 0  | 0  |
| h4      | 2  | ∞  | 2  | 2  | 2  |

| R1      | S0 | S1 | S2 | S3 | S4 |
|---------|----|----|----|----|----|
| updated | x  | x  |    |    |    |
| h1      | 1  | 3  | 1  | 1  | 1  |
| h2      | 1  | 1  | 3  | 3  | 3  |
| h3      | 0  | 2  | 0  | 0  | 0  |
| h4      | 0  | 0  | 2  | 2  | 2  |

| R2      | S0 | S1 | S2 | S3 | S4 |
|---------|----|----|----|----|----|
| updated |    |    |    | x  | x  |
| h1      | 1  | 3  | 1  | 1  | 1  |
| h2      | 1  | 1  | 3  | 0  | 0  |
| h3      | 0  | 2  | 0  | 0  | 0  |
| h4      | 0  | 0  | 2  | 1  | 1  |

| R3      | S0 | S1 | S2 | S3 | S4 |
|---------|----|----|----|----|----|
| updated | x  | x  |    |    |    |
| h1      | 0  | 0  | 1  | 1  | 1  |
| h2      | 1  | 1  | 3  | 0  | 0  |
| h3      | 0  | 1  | 0  | 0  | 0  |
| h4      | 0  | 0  | 2  | 1  | 1  |



b) Bruk LSH med to bånd og signaturene du nettopp har kommet frem til, for å finne sett med
Jaccard-likhet=SIM(Si,Sj)=1. Forklar hvordan du kommer frem til disse.

|        | S0 | S1 | S2 | S3 | S4 |
|--------|----|----|----|----|----|
| band 1 | 0  | 0  | 1  | 1  | 1  |
| band 1 | 1  | 1  | 3  | 0  | 0  |

| band 2 | 0  | 1  | 0  | 0  | 0  |
| band 2 | 0  | 0  | 2  | 1  | 1  |

find candidates by finding at least one similar pair of partial signatures

c
band 1:
candidates:
(s0,s1),(s3,s4)

band 2:
(s3,s4)


jaccard similarity: (original sets)
sim(s0,s1) = sim([1,1,0,1], [0,1,0,1])=2/3
sim(s3,s4) = sim([1,0,1,0],[1,0,1,0])=2/2=1

**answer: s3,s4**

# 3

<!-- generalized balance:

| advertiser | query | bid (x) | budget (b) | spent so far (m) | fraction left (f) ((b-m)/(b) |phi (x(1-e^(-f))  | allocated bidder |
|------------|-------|---------|------------|------------------|------------------------------|------------------|-----------------|
| a1         | q1    | 1       | 1          | 0                | 1                            |   0.632120559    |                 |
| a2         | q2    | 0.5     | 3          | 0                | 1                            | 0.316060279    |                 |
| a2         | q3    | 0.5     | 3          | 0                | 1                            | 0.5(|                 |
| a3         | q2    | 1       | 1          | 0                | 1                            | |                 |
| a4         | q1    | 0.75    | 2          | 0                | 1                            | |                 |
| a4         | q2    | 0.5     | 2          | 0                | 1                            | |                 |
| a4         | q4    | 0.5     | 2          | 0                | 1                            | |                 |
 -->

balance:
- for each query, pick advertiser with largest unspent budget
- break ties arbitrarily (but deterministically)

<!-- | query | candidates & bids | remaining budget | acc. income |
|-------|-------------------|------------------|-------------|
| q1    |                   |                  |             |
| q2    |                   |                  |             |
| q3    |                   |                  |             |
| q2    |                   |                  |             |
| q1    |                   |                  |             |
| q2    |                   |                  |             |
| q4    |                   |                  |             | -->

| Annonsør | Budsjett |
|----------|----------|
| a1       | 1        |
| a2       | 3        |
| a3       | 1        |
| a4       | 2        |

sorted by q
| annonsør | Spørring | Bud  |
|----------|----------|------|
| a1       | q1       | 1    |
| a4       | q1       | 0.75 |
| a2       | q2       | 0.5  |
| a3       | q2       | 1    |
| a4       | q2       | 0.5  |
| a2       | q3       | 0.5  |
| a4       | q4       | 0.5  |


remember to use specific query sequence if specified
| query | candidates & bids               | b1 | b2  | b3 | b4   | acc. income |
|-------|---------------------------------|----|-----|----|------|-------------|
|       |                                 | 1  | 3   | 1  | 2    | 0           |
| q1    | (a1, 1), **(a4, 0.75)**         |    |     |    | 1.25 | 0.75        |
| q2    | **(a2, 0.5)**, (a3, 1),(a4,0.5) |    | 2.5 |    |      | 1.25        |
| q4    | **(a4,0.5)**                    |    |     |    | 0.75 | 1.75        |
| q3    | **(a2,0.5)**                    |    | 2   |    |      | 2.25        |
| q2    | **(a2,0.5)**,(a3,1),(a4,0.5)    |    | 1.5 |    |      | 2.75        |
| q2    | **(a2,0.5)**,(a3,1),(a4,0.5)    |    | 0.5 |    |      | 3.25        |
| q3    | **(a2,0.5)**                    |    | 0   |    |      | 3.75        |
| q2    | (a2,0.5),**(a3,1)**,(a4,0.5)    |    |     | 0  |      | 4.75        |
| q2    | (a2,0.5),(a3,1),**(a4,0.5)**    |    |     |    | 0.25 | 5.25        |


# 4
## a) Drøft hvorfor system som f.eks. AsterixDB Feeds, Spark eller Storm er nødvendige for at håndtering av datastrøm skal være mulig. Forklar deretter hvilke fordeler og ulemper hver av disse nevnte systemene har.  

streaming frameworks are different in the way that they are able to handle large data at high volume, velocity, and variety.

Pros/cons


- storm vs spark
    - ![](../images/2022-02-07-11-17-51.png)
- storm
    - distributed real-time computation system
    - streams
        - sequence of tuples
    - spout
        - source of stream
    - bolts
        - functions that produce new streams
    - topology vs architecture
    - hierarchy of workers, supervisors, zookeepers, numbus

    - pros
        - real-time streaming
        - fault tolerance
            - automatic restart
        - scalability
        - ease of use
            - deploying/operation
        - built-in user defined functions
    - cons
        - no natural data storage and recovery handling
        - real-time focus means unable to implement windowing
- spark
    - pros
        - micro batching allowing natural windowing (sliding windows)
        - easy to use
        - connect to existing systems giving flexibility
    - cons
        - uses tuples, hard to implement java
        - micro-batching not easy to handle/analyze real-time
        - no natural data storage and recovery handling
        - single point of failiure in the stream


- asterixDB
    - for semi-structured data, data-intensive computing, parallell db systems
    - scalable storage/indexing
        - hash partitioning
        - lsm indexing
    - declarative query support
    - data feed (stream)
        - need data feed management
    - data ingestion support
    - cascading network of feeds
        - competing for resources
            - need data ingestion policy 
    - scalability acording to data ingestion
    - data indigestion
        - data may arrive faster than ability to pre-process
            - different policies for solving
    - fault tolerance
        - solft/hard failiure recovery
        - recovery from data ingestion


## b) Tegn og forklar systemarkitekturen til Storm (Tips: ikke topologi). 


## c) Forklar hva som menes med «Delivery Semantics (Message Guarantees)» for datastrøm. Bruk eksempler til å støtte forklaringen din.


## d) Vi skiller mellom «soft failure» og «hard failure» når vi snakker om feiltoleranse for et system for datastrøm. Forklar forskjellene mellom disse
Soft failiure is the inability to process a request, even though the nodes are working, while hard failiure is when nodes themself fail to work, and therefore cannot take any for of requests.


# 5
## a) Instagram-oppgaven kan løses ved hjelp av både stående spørring (standing queries) og ad-hoc spørring. Forklar hvordan.
ad-hoc:
number of comments last 24h for given sus user

standing:
all users with many comments last 24h




## b) Skisser en løsning for Instagram basert på glidende vinduer (sliding windows).
looking at a users' feed, generate bit stream with 0 for unliked, and 1 for liked images.
The window size should be time based in order to detect spam. Item-based will only detect users who like man of the photos they see, while time-based will detect users who like unnaturally many photos over short periods of time. The windows size can be 24 hours. It will then be possible to query how many likes a user has given in up to the past 24 hours.


## c) Kan Flajolet-Martin-algoritmen brukes her til å estimere antall «likes» til en bruker? Forklar
<!-- It can be used by creating a list of user-ids that have liked the users' photos, and then using that as an input. The output will then be the number of distinct users that have liked a post from the given user. -->

It can also be used by creating a list of the image stream, with only the liked images. The algorithm will then check how many of them are unique images.




# 6
## a
- find subgraph by bfs for each node
- calculate number of paths to each node
- calculate edge values from leaf to root:
    - all nodes have value 1
    - edge has the sum of edges and nodes from leaf
    - needs to be divided by number of incoming paths

| edges | edge betweenness |
|-------|------------------|
| AC    | 3+0+1+1+1+1+1=8  |
| AB    | 3+1+0+1+1+1+1=8  |
| CD    | 2+0+4+2+2+2+2=14 |
| BD    | 2+4+0+2+2+2+2=14 |
| DE    | 3+3+3+3+5+5+5=27 |
| EF    | 1+1+1+1+1+6+0=11 |
| EG    | 1+1+1+1+1+0+6=11 |
| BC    | 0+1+1+0+0+0+0=2  |
| FG    | 0+0+0+0+0+0+0=0  |

See drawing
